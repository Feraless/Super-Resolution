{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ea42433-75d6-48e7-a5d9-2f93fdd458e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ff9bad4-adcf-486a-aae2-5ad41b427528",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa1f465-7dba-4258-b9ef-3534038f8aa2",
   "metadata": {},
   "source": [
    "**Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c42e7ac7-6d9a-43de-8a93-a95edaeebcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "def load_images_from_folder(folder_path, target_size=(64, 64)):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        img = cv2.imread(os.path.join(folder_path, filename))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  \n",
    "        img = cv2.resize(img, target_size)\n",
    "        img = img.astype(np.float32) / 255.0  \n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "    \n",
    "folder_path = fr\"C:\\Users\\surri\\PycharmProjects\\Python Project\\Data 2\"\n",
    "high_res_images = load_images_from_folder(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccb93119-9eb4-4282-867b-b9d6c57b4cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blur_images(images, kernel_size=(5, 5)):\n",
    "    blurred_images = []\n",
    "    for img in images:\n",
    "        blurred_img = cv2.GaussianBlur(img, kernel_size, 0)\n",
    "        blurred_images.append(blurred_img)\n",
    "    return np.array(blurred_images)\n",
    "blurred_images = blur_images(high_res_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fae8299-11cb-4543-863d-909e25a24d4c",
   "metadata": {},
   "source": [
    "**Building the Generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5be4fbb2-c4cf-4870-9d4e-abbad996d342",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Dense,LeakyReLU,UpSampling2D,Flatten,Reshape,Input,BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d727713-955c-4b13-8f6c-cbdeb0de0eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, LeakyReLU, Add, BatchNormalization, UpSampling2D, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def build_generator():\n",
    "    input_lr = Input(shape=(64, 64, 3))\n",
    "    \n",
    "    # Encoder part\n",
    "    x = Conv2D(64, kernel_size=3, strides=1, padding='same')(input_lr)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = Conv2D(128, kernel_size=3, strides=2, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = Conv2D(128, kernel_size=3, strides=2, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = Conv2D(256, kernel_size=3, strides=2, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = Conv2D(256, kernel_size=3, strides=2, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # Bottleneck block\n",
    "    for _ in range(6):\n",
    "        residual = x\n",
    "        x = Conv2D(256, kernel_size=3, strides=1, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(alpha=0.2)(x)\n",
    "        x = Conv2D(256, kernel_size=3, strides=1, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Add()([x, residual])\n",
    "        x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # Decoder part\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(256, kernel_size=3, strides=1, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(128, kernel_size=3, strides=1, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(64, kernel_size=3, strides=1, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(64, kernel_size=3, strides=1, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    output_hr = Conv2D(3, kernel_size=3, activation='sigmoid', padding='same')(x)\n",
    "    generator = Model(input_lr, output_hr, name='generator') \n",
    "    return generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5e2661d-f53c-45e3-a966-2601c8f9b6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = build_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13c43a1d-32fb-4ffa-ab23-87f36983baad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 64, 64, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 64, 64, 64)   1792        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 64, 64, 64)   0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 32, 32, 128)  73856       ['leaky_re_lu[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 32, 32, 128)  512        ['conv2d_1[0][0]']               \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 32, 32, 128)  0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 16, 16, 128)  147584      ['leaky_re_lu_1[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 16, 16, 128)  512        ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 16, 16, 128)  0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 8, 8, 256)    295168      ['leaky_re_lu_2[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 8, 8, 256)   1024        ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)      (None, 8, 8, 256)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 4, 4, 256)    590080      ['leaky_re_lu_3[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 4, 4, 256)   1024        ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)      (None, 4, 4, 256)    0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 4, 4, 256)    590080      ['leaky_re_lu_4[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 4, 4, 256)   1024        ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)      (None, 4, 4, 256)    0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 4, 4, 256)    590080      ['leaky_re_lu_5[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 4, 4, 256)   1024        ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 4, 4, 256)    0           ['batch_normalization_5[0][0]',  \n",
      "                                                                  'leaky_re_lu_4[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_6 (LeakyReLU)      (None, 4, 4, 256)    0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 4, 4, 256)    590080      ['leaky_re_lu_6[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 4, 4, 256)   1024        ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_7 (LeakyReLU)      (None, 4, 4, 256)    0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 4, 4, 256)    590080      ['leaky_re_lu_7[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 4, 4, 256)   1024        ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 4, 4, 256)    0           ['batch_normalization_7[0][0]',  \n",
      "                                                                  'leaky_re_lu_6[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_8 (LeakyReLU)      (None, 4, 4, 256)    0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 4, 4, 256)    590080      ['leaky_re_lu_8[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 4, 4, 256)   1024        ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_9 (LeakyReLU)      (None, 4, 4, 256)    0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 4, 4, 256)    590080      ['leaky_re_lu_9[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 4, 4, 256)   1024        ['conv2d_10[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 4, 4, 256)    0           ['batch_normalization_9[0][0]',  \n",
      "                                                                  'leaky_re_lu_8[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_10 (LeakyReLU)     (None, 4, 4, 256)    0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 4, 4, 256)    590080      ['leaky_re_lu_10[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_11 (LeakyReLU)     (None, 4, 4, 256)    0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 4, 4, 256)    590080      ['leaky_re_lu_11[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 4, 4, 256)    0           ['batch_normalization_11[0][0]', \n",
      "                                                                  'leaky_re_lu_10[0][0]']         \n",
      "                                                                                                  \n",
      " leaky_re_lu_12 (LeakyReLU)     (None, 4, 4, 256)    0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 4, 4, 256)    590080      ['leaky_re_lu_12[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_13 (LeakyReLU)     (None, 4, 4, 256)    0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 4, 4, 256)    590080      ['leaky_re_lu_13[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 4, 4, 256)    0           ['batch_normalization_13[0][0]', \n",
      "                                                                  'leaky_re_lu_12[0][0]']         \n",
      "                                                                                                  \n",
      " leaky_re_lu_14 (LeakyReLU)     (None, 4, 4, 256)    0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 4, 4, 256)    590080      ['leaky_re_lu_14[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_15 (LeakyReLU)     (None, 4, 4, 256)    0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 4, 4, 256)    590080      ['leaky_re_lu_15[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 4, 4, 256)    0           ['batch_normalization_15[0][0]', \n",
      "                                                                  'leaky_re_lu_14[0][0]']         \n",
      "                                                                                                  \n",
      " leaky_re_lu_16 (LeakyReLU)     (None, 4, 4, 256)    0           ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 8, 8, 256)    0           ['leaky_re_lu_16[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 8, 8, 256)    590080      ['up_sampling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_17 (LeakyReLU)     (None, 8, 8, 256)    0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSampling2D)  (None, 16, 16, 256)  0          ['leaky_re_lu_17[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 16, 16, 128)  295040      ['up_sampling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 16, 16, 128)  512        ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_18 (LeakyReLU)     (None, 16, 16, 128)  0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSampling2D)  (None, 32, 32, 128)  0          ['leaky_re_lu_18[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 32, 32, 64)   73792       ['up_sampling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 32, 32, 64)  256         ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_19 (LeakyReLU)     (None, 32, 32, 64)   0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSampling2D)  (None, 64, 64, 64)  0           ['leaky_re_lu_19[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 64, 64, 64)   36928       ['up_sampling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 64, 64, 64)  256         ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_20 (LeakyReLU)     (None, 64, 64, 64)   0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 64, 64, 3)    1731        ['leaky_re_lu_20[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 9,204,419\n",
      "Trainable params: 9,195,715\n",
      "Non-trainable params: 8,704\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ca0d30-e82a-4428-a164-83e84a81c1f9",
   "metadata": {},
   "source": [
    "**Build Discriminator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88f8bbcf-30b0-4295-8718-1e9210bbefe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e674328c-b1a7-45ba-ae58-af2575723e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_44 (Conv2D)          (None, 32, 32, 256)       12544     \n",
      "                                                                 \n",
      " leaky_re_lu_42 (LeakyReLU)  (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " conv2d_45 (Conv2D)          (None, 16, 16, 256)       1048832   \n",
      "                                                                 \n",
      " batch_normalization_40 (Bat  (None, 16, 16, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_43 (LeakyReLU)  (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " conv2d_46 (Conv2D)          (None, 8, 8, 128)         524416    \n",
      "                                                                 \n",
      " batch_normalization_41 (Bat  (None, 8, 8, 128)        512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_44 (LeakyReLU)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv2d_47 (Conv2D)          (None, 4, 4, 128)         262272    \n",
      "                                                                 \n",
      " batch_normalization_42 (Bat  (None, 4, 4, 128)        512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_45 (LeakyReLU)  (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " conv2d_48 (Conv2D)          (None, 2, 2, 64)          131136    \n",
      "                                                                 \n",
      " batch_normalization_43 (Bat  (None, 2, 2, 64)         256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_46 (LeakyReLU)  (None, 2, 2, 64)          0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 2, 2, 64)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,981,761\n",
      "Trainable params: 1,980,609\n",
      "Non-trainable params: 1,152\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_discriminator():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(256, kernel_size=4, strides=2, padding=\"same\", input_shape=(64, 64, 3)))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    model.add(Conv2D(256, kernel_size=4, strides=2, padding=\"same\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    model.add(Conv2D(128, kernel_size=4, strides=2, padding=\"same\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    model.add(Conv2D(128, kernel_size=4, strides=2, padding=\"same\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size=4, strides=2, padding=\"same\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    return model\n",
    "    \n",
    "discriminator = build_discriminator()\n",
    "discriminator.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec55450-340a-4e2c-94ec-3b67087c10f9",
   "metadata": {},
   "source": [
    "**Create Custom Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d526e6e-4c44-4dbd-82db-53a3a2c51dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f90e79f9-f3e2-4a47-85e2-ea6cd730b356",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_opt = Adam(0.0001)\n",
    "d_opt = Adam(0.00001)\n",
    "g_loss = BinaryCrossentropy()\n",
    "d_loss = BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d02f85a2-3086-4f7d-85f7-91b748526e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Super_Res(Model):\n",
    "\n",
    "    def __init__(self, generator, discriminator, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        \n",
    "    def compile(self, g_opt, d_opt, g_loss, d_loss, *args, **kwargs):\n",
    "        super().compile(*args, **kwargs)\n",
    "        self.g_opt = g_opt\n",
    "        self.d_opt = d_opt\n",
    "        self.g_loss = g_loss\n",
    "        self.d_loss = d_loss\n",
    "\n",
    "    def train_step(self, data):\n",
    "        real_images, blurred_images = data\n",
    "        fake_images = self.generator(blurred_images, training=False)\n",
    "\n",
    "        with tf.GradientTape() as d_tape:\n",
    "            yhat_real = self.discriminator(real_images, training=True)\n",
    "            yhat_fake = self.discriminator(fake_images, training=True)\n",
    "            yhat_realfake = tf.concat([yhat_real, yhat_fake], axis=0)\n",
    "            y_realfake = tf.concat([tf.zeros_like(yhat_real), tf.ones_like(yhat_fake)], axis=0)\n",
    "            noise_real = 0.1*tf.random.uniform(tf.shape(yhat_real))\n",
    "            noise_fake = -0.1*tf.random.uniform(tf.shape(yhat_fake))\n",
    "            y_realfake += tf.concat([noise_real, noise_fake], axis=0)\n",
    "            total_d_loss = self.d_loss(y_realfake, yhat_realfake)\n",
    "\n",
    "        dgrad = d_tape.gradient(total_d_loss, self.discriminator.trainable_variables)\n",
    "        self.d_opt.apply_gradients(zip(dgrad, self.discriminator.trainable_variables))\n",
    "\n",
    "        with tf.GradientTape() as g_tape:\n",
    "            gen_images = self.generator(blurred_images, training=True)\n",
    "            predicted_labels = self.discriminator(gen_images, training=False)\n",
    "            total_g_loss = self.g_loss(tf.zeros_like(predicted_labels), predicted_labels)\n",
    "\n",
    "        ggrad = g_tape.gradient(total_g_loss, self.generator.trainable_variables)\n",
    "        self.g_opt.apply_gradients(zip(ggrad, self.generator.trainable_variables))\n",
    "\n",
    "        return {\"d_loss\": total_d_loss, \"g_loss\": total_g_loss}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974cc262-9baa-4db4-a597-be69989f0f23",
   "metadata": {},
   "source": [
    "**Training the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7a74c6b-bc47-41df-822f-5819de9b7b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "super_res_model = Super_Res(generator, discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34213072-fb3e-4557-bb1f-27cad0e82957",
   "metadata": {},
   "outputs": [],
   "source": [
    "super_res_model.compile(g_opt, d_opt, g_loss, d_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5818ea25-8e2d-4a0d-aa8e-e88ad7d0a13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, d_loss: 0.9130052328109741, g_loss: 0.04972480982542038\n",
      "Epoch 2, d_loss: 0.7131525278091431, g_loss: 0.0026331671979278326\n",
      "Epoch 3, d_loss: 0.4677678644657135, g_loss: 0.0006547514931298792\n",
      "Epoch 4, d_loss: 0.46129879355430603, g_loss: 0.0007101114606484771\n",
      "Epoch 5, d_loss: 0.49202480912208557, g_loss: 0.0010312676895409822\n",
      "Epoch 6, d_loss: 0.6264033317565918, g_loss: 0.0010316673433408141\n",
      "Epoch 7, d_loss: 0.6871498823165894, g_loss: 0.0011519469553604722\n",
      "Epoch 8, d_loss: 0.887736439704895, g_loss: 0.00137179100420326\n",
      "Epoch 9, d_loss: 0.7814577221870422, g_loss: 0.0013565723784267902\n",
      "Epoch 10, d_loss: 0.6798390746116638, g_loss: 0.001965646632015705\n",
      "Epoch 11, d_loss: 0.6022716164588928, g_loss: 0.0029916740022599697\n",
      "Epoch 12, d_loss: 0.612019956111908, g_loss: 0.002687879139557481\n",
      "Epoch 13, d_loss: 0.6277465224266052, g_loss: 0.001964757451787591\n",
      "Epoch 14, d_loss: 0.4983743131160736, g_loss: 0.0018301131203770638\n",
      "Epoch 15, d_loss: 0.577125072479248, g_loss: 0.0023416096810251474\n",
      "Epoch 16, d_loss: 0.5207846760749817, g_loss: 0.0023694904521107674\n",
      "Epoch 17, d_loss: 0.5335100889205933, g_loss: 0.002261783229187131\n",
      "Epoch 18, d_loss: 0.3904966115951538, g_loss: 0.0023917502257972956\n",
      "Epoch 19, d_loss: 0.38394245505332947, g_loss: 0.0023569464683532715\n",
      "Epoch 20, d_loss: 0.33662936091423035, g_loss: 0.002043931744992733\n"
     ]
    }
   ],
   "source": [
    "batch_size = 31\n",
    "num_epochs = 20\n",
    "\n",
    "num_batches = len(high_res_images) // batch_size\n",
    "high_res_batches = np.array_split(high_res_images[:num_batches * batch_size], num_batches)\n",
    "blurred_batches = np.array_split(blurred_images[:num_batches * batch_size], num_batches)\n",
    "for epoch in range(num_epochs):\n",
    "        for high_res_batch, blurred_batch in zip(high_res_batches, blurred_batches):\n",
    "            loss = super_res_model.train_step((high_res_batch, blurred_batch))\n",
    "        print(f\"Epoch {epoch + 1}, d_loss: {loss['d_loss']}, g_loss: {loss['g_loss']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
